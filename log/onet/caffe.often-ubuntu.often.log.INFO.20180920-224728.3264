Log file created at: 2018/09/20 22:47:28
Running on machine: often-ubuntu
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0920 22:47:28.532120  3264 upgrade_proto.cpp:1113] snapshot_prefix was a directory and is replaced to ../tmp/model/onet/0920/solver
I0920 22:47:28.532266  3264 caffe.cpp:200] Use CPU.
I0920 22:47:28.731884  3264 solver.cpp:45] Initializing solver from parameters: 
base_lr: 0.01
display: 200
max_iter: 200000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.004
stepsize: 20000
snapshot: 10000
snapshot_prefix: "../tmp/model/onet/0920/solver"
solver_mode: CPU
net: "train_onet.prototxt"
train_state {
  level: 0
  stage: ""
}
I0920 22:47:28.732055  3264 solver.cpp:102] Creating training net from net file: train_onet.prototxt
I0920 22:47:28.732592  3264 net.cpp:51] Initializing net from parameters: 
name: "ONet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "PyData"
  type: "Python"
  top: "data"
  top: "label"
  top: "bbox"
  top: "landmark"
  python_param {
    module: "pydata_layer_multidb"
    layer: "MtcnnDataLayer"
    param_str: "{\'batch_size\': 384, \'net_type\': \'onet\'}"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    kernel_size: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu4"
  type: "PReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "InnerProduct"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "drop5"
  type: "Dropout"
  bottom: "conv5"
  top: "conv5"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "prelu5"
  type: "PReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6-1"
  type: "InnerProduct"
  bottom: "conv5"
  top: "conv6-1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "cls_bridge"
  type: "OftenMtcnnClassBridge"
  bottom: "conv6-1"
  bottom: "label"
  top: "conv6-1-valid"
  top: "label-valid"
  propagate_down: true
  propagate_down: false
}
layer {
  name: "cls_loss"
  type: "OftenMtcnnSoftmaxLoss"
  bottom: "conv6-1-valid"
  bottom: "label-valid"
  top: "cls_loss"
  propagate_down: true
  propagate_down: false
}
layer {
  name: "cls_Acc"
  type: "OftenMtcnnAccuracy"
  bottom: "conv6-1-valid"
  bottom: "label-valid"
  top: "cls_Acc"
  include {
    phase: TRAIN
  }
}
layer {
  name: "conv6-2"
  type: "InnerProduct"
  bottom: "conv5"
  top: "conv6-2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_loss"
  type: "OftenMtcnnEuclideanLoss"
  bottom: "conv6-2"
  bottom: "bbox"
  bottom: "label"
  top: "bbox_loss"
  loss_weight: 0.5
  propagate_down: true
  propagate_down: false
  propagate_down: false
}
layer {
  name: "conv6-3"
  type: "InnerProduct"
  bottom: "conv5"
  top: "conv6-3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "landmark_loss"
  type: "OftenMtcnnLandMarkLoss"
  bottom: "conv6-3"
  bottom: "landmark"
  bottom: "label"
  top: "landmark_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  propagate_down: false
}
I0920 22:47:28.733198  3264 layer_factory.hpp:78] Creating layer PyData
I0920 22:47:29.488750  3264 net.cpp:84] Creating Layer PyData
I0920 22:47:29.488795  3264 net.cpp:380] PyData -> data
I0920 22:47:29.488952  3264 net.cpp:380] PyData -> label
I0920 22:47:29.488991  3264 net.cpp:380] PyData -> bbox
I0920 22:47:29.489013  3264 net.cpp:380] PyData -> landmark
I0920 22:47:29.504902  3264 net.cpp:122] Setting up PyData
I0920 22:47:29.504974  3264 net.cpp:129] Top shape: 384 3 48 48 (2654208)
I0920 22:47:29.504984  3264 net.cpp:129] Top shape: 384 (384)
I0920 22:47:29.504989  3264 net.cpp:129] Top shape: 384 4 (1536)
I0920 22:47:29.505000  3264 net.cpp:129] Top shape: 384 10 (3840)
I0920 22:47:29.505003  3264 net.cpp:137] Memory required for data: 10639872
I0920 22:47:29.505045  3264 layer_factory.hpp:78] Creating layer label_PyData_1_split
I0920 22:47:29.505108  3264 net.cpp:84] Creating Layer label_PyData_1_split
I0920 22:47:29.505131  3264 net.cpp:406] label_PyData_1_split <- label
I0920 22:47:29.505183  3264 net.cpp:380] label_PyData_1_split -> label_PyData_1_split_0
I0920 22:47:29.505215  3264 net.cpp:380] label_PyData_1_split -> label_PyData_1_split_1
I0920 22:47:29.505235  3264 net.cpp:380] label_PyData_1_split -> label_PyData_1_split_2
I0920 22:47:29.505271  3264 net.cpp:122] Setting up label_PyData_1_split
I0920 22:47:29.505280  3264 net.cpp:129] Top shape: 384 (384)
I0920 22:47:29.505285  3264 net.cpp:129] Top shape: 384 (384)
I0920 22:47:29.505290  3264 net.cpp:129] Top shape: 384 (384)
I0920 22:47:29.505292  3264 net.cpp:137] Memory required for data: 10644480
I0920 22:47:29.505300  3264 layer_factory.hpp:78] Creating layer conv1
I0920 22:47:29.505345  3264 net.cpp:84] Creating Layer conv1
I0920 22:47:29.505353  3264 net.cpp:406] conv1 <- data
I0920 22:47:29.505369  3264 net.cpp:380] conv1 -> conv1
I0920 22:47:30.019134  3264 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 207012
I0920 22:47:30.019281  3264 net.cpp:122] Setting up conv1
I0920 22:47:30.019309  3264 net.cpp:129] Top shape: 384 32 46 46 (26001408)
I0920 22:47:30.019312  3264 net.cpp:137] Memory required for data: 114650112
I0920 22:47:30.019424  3264 layer_factory.hpp:78] Creating layer prelu1
I0920 22:47:30.019460  3264 net.cpp:84] Creating Layer prelu1
I0920 22:47:30.019472  3264 net.cpp:406] prelu1 <- conv1
I0920 22:47:30.019491  3264 net.cpp:367] prelu1 -> conv1 (in-place)
I0920 22:47:30.019723  3264 net.cpp:122] Setting up prelu1
I0920 22:47:30.019731  3264 net.cpp:129] Top shape: 384 32 46 46 (26001408)
I0920 22:47:30.019734  3264 net.cpp:137] Memory required for data: 218655744
I0920 22:47:30.019773  3264 layer_factory.hpp:78] Creating layer pool1
I0920 22:47:30.019840  3264 net.cpp:84] Creating Layer pool1
I0920 22:47:30.019860  3264 net.cpp:406] pool1 <- conv1
I0920 22:47:30.019872  3264 net.cpp:380] pool1 -> pool1
I0920 22:47:30.019912  3264 net.cpp:122] Setting up pool1
I0920 22:47:30.019920  3264 net.cpp:129] Top shape: 384 32 23 23 (6500352)
I0920 22:47:30.019924  3264 net.cpp:137] Memory required for data: 244657152
I0920 22:47:30.019932  3264 layer_factory.hpp:78] Creating layer conv2
I0920 22:47:30.019951  3264 net.cpp:84] Creating Layer conv2
I0920 22:47:30.019958  3264 net.cpp:406] conv2 <- pool1
I0920 22:47:30.019971  3264 net.cpp:380] conv2 -> conv2
I0920 22:47:30.021373  3264 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 615168
I0920 22:47:30.021508  3264 net.cpp:122] Setting up conv2
I0920 22:47:30.021522  3264 net.cpp:129] Top shape: 384 64 21 21 (10838016)
I0920 22:47:30.021525  3264 net.cpp:137] Memory required for data: 288009216
I0920 22:47:30.021546  3264 layer_factory.hpp:78] Creating layer prelu2
I0920 22:47:30.021562  3264 net.cpp:84] Creating Layer prelu2
I0920 22:47:30.021571  3264 net.cpp:406] prelu2 <- conv2
I0920 22:47:30.021585  3264 net.cpp:367] prelu2 -> conv2 (in-place)
I0920 22:47:30.021689  3264 net.cpp:122] Setting up prelu2
I0920 22:47:30.021698  3264 net.cpp:129] Top shape: 384 64 21 21 (10838016)
I0920 22:47:30.021701  3264 net.cpp:137] Memory required for data: 331361280
I0920 22:47:30.021710  3264 layer_factory.hpp:78] Creating layer pool2
I0920 22:47:30.021721  3264 net.cpp:84] Creating Layer pool2
I0920 22:47:30.021728  3264 net.cpp:406] pool2 <- conv2
I0920 22:47:30.021757  3264 net.cpp:380] pool2 -> pool2
I0920 22:47:30.021793  3264 net.cpp:122] Setting up pool2
I0920 22:47:30.021800  3264 net.cpp:129] Top shape: 384 64 10 10 (2457600)
I0920 22:47:30.021805  3264 net.cpp:137] Memory required for data: 341191680
I0920 22:47:30.021811  3264 layer_factory.hpp:78] Creating layer conv3
I0920 22:47:30.021859  3264 net.cpp:84] Creating Layer conv3
I0920 22:47:30.021867  3264 net.cpp:406] conv3 <- pool2
I0920 22:47:30.021883  3264 net.cpp:380] conv3 -> conv3
I0920 22:47:30.023953  3264 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1229568
I0920 22:47:30.023973  3264 net.cpp:122] Setting up conv3
I0920 22:47:30.023998  3264 net.cpp:129] Top shape: 384 64 8 8 (1572864)
I0920 22:47:30.024003  3264 net.cpp:137] Memory required for data: 347483136
I0920 22:47:30.024029  3264 layer_factory.hpp:78] Creating layer prelu3
I0920 22:47:30.024056  3264 net.cpp:84] Creating Layer prelu3
I0920 22:47:30.024076  3264 net.cpp:406] prelu3 <- conv3
I0920 22:47:30.024103  3264 net.cpp:367] prelu3 -> conv3 (in-place)
I0920 22:47:30.024175  3264 net.cpp:122] Setting up prelu3
I0920 22:47:30.024183  3264 net.cpp:129] Top shape: 384 64 8 8 (1572864)
I0920 22:47:30.024200  3264 net.cpp:137] Memory required for data: 353774592
I0920 22:47:30.024215  3264 layer_factory.hpp:78] Creating layer pool3
I0920 22:47:30.024230  3264 net.cpp:84] Creating Layer pool3
I0920 22:47:30.024237  3264 net.cpp:406] pool3 <- conv3
I0920 22:47:30.024250  3264 net.cpp:380] pool3 -> pool3
I0920 22:47:30.024271  3264 net.cpp:122] Setting up pool3
I0920 22:47:30.024279  3264 net.cpp:129] Top shape: 384 64 4 4 (393216)
I0920 22:47:30.024283  3264 net.cpp:137] Memory required for data: 355347456
I0920 22:47:30.024288  3264 layer_factory.hpp:78] Creating layer conv4
I0920 22:47:30.024304  3264 net.cpp:84] Creating Layer conv4
I0920 22:47:30.024312  3264 net.cpp:406] conv4 <- pool3
I0920 22:47:30.024327  3264 net.cpp:380] conv4 -> conv4
I0920 22:47:30.026679  3264 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6840
I0920 22:47:30.026862  3264 net.cpp:122] Setting up conv4
I0920 22:47:30.026878  3264 net.cpp:129] Top shape: 384 128 3 3 (442368)
I0920 22:47:30.026885  3264 net.cpp:137] Memory required for data: 357116928
I0920 22:47:30.026909  3264 layer_factory.hpp:78] Creating layer prelu4
I0920 22:47:30.026929  3264 net.cpp:84] Creating Layer prelu4
I0920 22:47:30.026942  3264 net.cpp:406] prelu4 <- conv4
I0920 22:47:30.026983  3264 net.cpp:367] prelu4 -> conv4 (in-place)
I0920 22:47:30.027040  3264 net.cpp:122] Setting up prelu4
I0920 22:47:30.027050  3264 net.cpp:129] Top shape: 384 128 3 3 (442368)
I0920 22:47:30.027057  3264 net.cpp:137] Memory required for data: 358886400
I0920 22:47:30.027071  3264 layer_factory.hpp:78] Creating layer conv5
I0920 22:47:30.027098  3264 net.cpp:84] Creating Layer conv5
I0920 22:47:30.027109  3264 net.cpp:406] conv5 <- conv4
I0920 22:47:30.027132  3264 net.cpp:380] conv5 -> conv5
I0920 22:47:30.039780  3264 net.cpp:122] Setting up conv5
I0920 22:47:30.039813  3264 net.cpp:129] Top shape: 384 256 (98304)
I0920 22:47:30.039834  3264 net.cpp:137] Memory required for data: 359279616
I0920 22:47:30.039880  3264 layer_factory.hpp:78] Creating layer drop5
I0920 22:47:30.039923  3264 net.cpp:84] Creating Layer drop5
I0920 22:47:30.039937  3264 net.cpp:406] drop5 <- conv5
I0920 22:47:30.039959  3264 net.cpp:367] drop5 -> conv5 (in-place)
I0920 22:47:30.040001  3264 net.cpp:122] Setting up drop5
I0920 22:47:30.040009  3264 net.cpp:129] Top shape: 384 256 (98304)
I0920 22:47:30.040012  3264 net.cpp:137] Memory required for data: 359672832
I0920 22:47:30.040017  3264 layer_factory.hpp:78] Creating layer prelu5
I0920 22:47:30.040042  3264 net.cpp:84] Creating Layer prelu5
I0920 22:47:30.040050  3264 net.cpp:406] prelu5 <- conv5
I0920 22:47:30.040061  3264 net.cpp:367] prelu5 -> conv5 (in-place)
I0920 22:47:30.040094  3264 net.cpp:122] Setting up prelu5
I0920 22:47:30.040102  3264 net.cpp:129] Top shape: 384 256 (98304)
I0920 22:47:30.040105  3264 net.cpp:137] Memory required for data: 360066048
I0920 22:47:30.040117  3264 layer_factory.hpp:78] Creating layer conv5_prelu5_0_split
I0920 22:47:30.040135  3264 net.cpp:84] Creating Layer conv5_prelu5_0_split
I0920 22:47:30.040144  3264 net.cpp:406] conv5_prelu5_0_split <- conv5
I0920 22:47:30.040164  3264 net.cpp:380] conv5_prelu5_0_split -> conv5_prelu5_0_split_0
I0920 22:47:30.040190  3264 net.cpp:380] conv5_prelu5_0_split -> conv5_prelu5_0_split_1
I0920 22:47:30.040223  3264 net.cpp:380] conv5_prelu5_0_split -> conv5_prelu5_0_split_2
I0920 22:47:30.040246  3264 net.cpp:122] Setting up conv5_prelu5_0_split
I0920 22:47:30.040256  3264 net.cpp:129] Top shape: 384 256 (98304)
I0920 22:47:30.040263  3264 net.cpp:129] Top shape: 384 256 (98304)
I0920 22:47:30.040268  3264 net.cpp:129] Top shape: 384 256 (98304)
I0920 22:47:30.040271  3264 net.cpp:137] Memory required for data: 361245696
I0920 22:47:30.040278  3264 layer_factory.hpp:78] Creating layer conv6-1
I0920 22:47:30.040295  3264 net.cpp:84] Creating Layer conv6-1
I0920 22:47:30.040303  3264 net.cpp:406] conv6-1 <- conv5_prelu5_0_split_0
I0920 22:47:30.040320  3264 net.cpp:380] conv6-1 -> conv6-1
I0920 22:47:30.040418  3264 net.cpp:122] Setting up conv6-1
I0920 22:47:30.040450  3264 net.cpp:129] Top shape: 384 2 (768)
I0920 22:47:30.040457  3264 net.cpp:137] Memory required for data: 361248768
I0920 22:47:30.040483  3264 layer_factory.hpp:78] Creating layer cls_bridge
I0920 22:47:30.040518  3264 net.cpp:84] Creating Layer cls_bridge
I0920 22:47:30.040525  3264 net.cpp:406] cls_bridge <- conv6-1
I0920 22:47:30.040539  3264 net.cpp:406] cls_bridge <- label_PyData_1_split_0
I0920 22:47:30.040555  3264 net.cpp:380] cls_bridge -> conv6-1-valid
I0920 22:47:30.040572  3264 net.cpp:380] cls_bridge -> label-valid
I0920 22:47:30.040585  3264 often_mtcnn_classbridge_layer.cpp:17] Often Mtcnn Bridge.
I0920 22:47:30.040599  3264 net.cpp:122] Setting up cls_bridge
I0920 22:47:30.040606  3264 net.cpp:129] Top shape: 384 2 (768)
I0920 22:47:30.040612  3264 net.cpp:129] Top shape: 384 (384)
I0920 22:47:30.040616  3264 net.cpp:137] Memory required for data: 361253376
I0920 22:47:30.040627  3264 layer_factory.hpp:78] Creating layer conv6-1-valid_cls_bridge_0_split
I0920 22:47:30.040642  3264 net.cpp:84] Creating Layer conv6-1-valid_cls_bridge_0_split
I0920 22:47:30.040652  3264 net.cpp:406] conv6-1-valid_cls_bridge_0_split <- conv6-1-valid
I0920 22:47:30.040671  3264 net.cpp:380] conv6-1-valid_cls_bridge_0_split -> conv6-1-valid_cls_bridge_0_split_0
I0920 22:47:30.040714  3264 net.cpp:380] conv6-1-valid_cls_bridge_0_split -> conv6-1-valid_cls_bridge_0_split_1
I0920 22:47:30.040735  3264 net.cpp:122] Setting up conv6-1-valid_cls_bridge_0_split
I0920 22:47:30.040742  3264 net.cpp:129] Top shape: 384 2 (768)
I0920 22:47:30.040748  3264 net.cpp:129] Top shape: 384 2 (768)
I0920 22:47:30.040752  3264 net.cpp:137] Memory required for data: 361259520
I0920 22:47:30.040760  3264 layer_factory.hpp:78] Creating layer label-valid_cls_bridge_1_split
I0920 22:47:30.040771  3264 net.cpp:84] Creating Layer label-valid_cls_bridge_1_split
I0920 22:47:30.040777  3264 net.cpp:406] label-valid_cls_bridge_1_split <- label-valid
I0920 22:47:30.040792  3264 net.cpp:380] label-valid_cls_bridge_1_split -> label-valid_cls_bridge_1_split_0
I0920 22:47:30.040810  3264 net.cpp:380] label-valid_cls_bridge_1_split -> label-valid_cls_bridge_1_split_1
I0920 22:47:30.040828  3264 net.cpp:122] Setting up label-valid_cls_bridge_1_split
I0920 22:47:30.040837  3264 net.cpp:129] Top shape: 384 (384)
I0920 22:47:30.040843  3264 net.cpp:129] Top shape: 384 (384)
I0920 22:47:30.040846  3264 net.cpp:137] Memory required for data: 361262592
I0920 22:47:30.040853  3264 layer_factory.hpp:78] Creating layer cls_loss
I0920 22:47:30.040876  3264 net.cpp:84] Creating Layer cls_loss
I0920 22:47:30.040887  3264 net.cpp:406] cls_loss <- conv6-1-valid_cls_bridge_0_split_0
I0920 22:47:30.040901  3264 net.cpp:406] cls_loss <- label-valid_cls_bridge_1_split_0
I0920 22:47:30.040917  3264 net.cpp:380] cls_loss -> cls_loss
I0920 22:47:30.040940  3264 layer_factory.hpp:78] Creating layer cls_loss
I0920 22:47:30.041316  3264 net.cpp:122] Setting up cls_loss
I0920 22:47:30.041328  3264 net.cpp:129] Top shape: (1)
I0920 22:47:30.041333  3264 net.cpp:132]     with loss weight 1
I0920 22:47:30.041353  3264 net.cpp:137] Memory required for data: 361262596
I0920 22:47:30.041362  3264 layer_factory.hpp:78] Creating layer cls_Acc
I0920 22:47:30.041378  3264 net.cpp:84] Creating Layer cls_Acc
I0920 22:47:30.041386  3264 net.cpp:406] cls_Acc <- conv6-1-valid_cls_bridge_0_split_1
I0920 22:47:30.041402  3264 net.cpp:406] cls_Acc <- label-valid_cls_bridge_1_split_1
I0920 22:47:30.041448  3264 net.cpp:380] cls_Acc -> cls_Acc
I0920 22:47:30.041491  3264 net.cpp:122] Setting up cls_Acc
I0920 22:47:30.041512  3264 net.cpp:129] Top shape: (1)
I0920 22:47:30.041517  3264 net.cpp:137] Memory required for data: 361262600
I0920 22:47:30.041525  3264 layer_factory.hpp:78] Creating layer conv6-2
I0920 22:47:30.041538  3264 net.cpp:84] Creating Layer conv6-2
I0920 22:47:30.041545  3264 net.cpp:406] conv6-2 <- conv5_prelu5_0_split_1
I0920 22:47:30.041574  3264 net.cpp:380] conv6-2 -> conv6-2
I0920 22:47:30.041667  3264 net.cpp:122] Setting up conv6-2
I0920 22:47:30.041677  3264 net.cpp:129] Top shape: 384 4 (1536)
I0920 22:47:30.041682  3264 net.cpp:137] Memory required for data: 361268744
I0920 22:47:30.041698  3264 layer_factory.hpp:78] Creating layer bbox_loss
I0920 22:47:30.041748  3264 net.cpp:84] Creating Layer bbox_loss
I0920 22:47:30.041759  3264 net.cpp:406] bbox_loss <- conv6-2
I0920 22:47:30.041772  3264 net.cpp:406] bbox_loss <- bbox
I0920 22:47:30.041779  3264 net.cpp:406] bbox_loss <- label_PyData_1_split_1
I0920 22:47:30.041791  3264 net.cpp:380] bbox_loss -> bbox_loss
I0920 22:47:30.041813  3264 net.cpp:122] Setting up bbox_loss
I0920 22:47:30.041821  3264 net.cpp:129] Top shape: (1)
I0920 22:47:30.041824  3264 net.cpp:132]     with loss weight 0.5
I0920 22:47:30.041831  3264 net.cpp:137] Memory required for data: 361268748
I0920 22:47:30.041836  3264 layer_factory.hpp:78] Creating layer conv6-3
I0920 22:47:30.041851  3264 net.cpp:84] Creating Layer conv6-3
I0920 22:47:30.041857  3264 net.cpp:406] conv6-3 <- conv5_prelu5_0_split_2
I0920 22:47:30.041874  3264 net.cpp:380] conv6-3 -> conv6-3
I0920 22:47:30.042052  3264 net.cpp:122] Setting up conv6-3
I0920 22:47:30.042062  3264 net.cpp:129] Top shape: 384 10 (3840)
I0920 22:47:30.042066  3264 net.cpp:137] Memory required for data: 361284108
I0920 22:47:30.042102  3264 layer_factory.hpp:78] Creating layer landmark_loss
I0920 22:47:30.042120  3264 net.cpp:84] Creating Layer landmark_loss
I0920 22:47:30.042129  3264 net.cpp:406] landmark_loss <- conv6-3
I0920 22:47:30.042140  3264 net.cpp:406] landmark_loss <- landmark
I0920 22:47:30.042147  3264 net.cpp:406] landmark_loss <- label_PyData_1_split_2
I0920 22:47:30.042158  3264 net.cpp:380] landmark_loss -> landmark_loss
I0920 22:47:30.042181  3264 net.cpp:122] Setting up landmark_loss
I0920 22:47:30.042187  3264 net.cpp:129] Top shape: (1)
I0920 22:47:30.042191  3264 net.cpp:132]     with loss weight 1
I0920 22:47:30.042210  3264 net.cpp:137] Memory required for data: 361284112
I0920 22:47:30.042217  3264 net.cpp:198] landmark_loss needs backward computation.
I0920 22:47:30.042238  3264 net.cpp:198] conv6-3 needs backward computation.
I0920 22:47:30.042243  3264 net.cpp:198] bbox_loss needs backward computation.
I0920 22:47:30.042249  3264 net.cpp:198] conv6-2 needs backward computation.
I0920 22:47:30.042254  3264 net.cpp:200] cls_Acc does not need backward computation.
I0920 22:47:30.042259  3264 net.cpp:198] cls_loss needs backward computation.
I0920 22:47:30.042266  3264 net.cpp:200] label-valid_cls_bridge_1_split does not need backward computation.
I0920 22:47:30.042273  3264 net.cpp:198] conv6-1-valid_cls_bridge_0_split needs backward computation.
I0920 22:47:30.042277  3264 net.cpp:198] cls_bridge needs backward computation.
I0920 22:47:30.042284  3264 net.cpp:198] conv6-1 needs backward computation.
I0920 22:47:30.042289  3264 net.cpp:198] conv5_prelu5_0_split needs backward computation.
I0920 22:47:30.042292  3264 net.cpp:198] prelu5 needs backward computation.
I0920 22:47:30.042299  3264 net.cpp:198] drop5 needs backward computation.
I0920 22:47:30.042302  3264 net.cpp:198] conv5 needs backward computation.
I0920 22:47:30.042307  3264 net.cpp:198] prelu4 needs backward computation.
I0920 22:47:30.042311  3264 net.cpp:198] conv4 needs backward computation.
I0920 22:47:30.042316  3264 net.cpp:198] pool3 needs backward computation.
I0920 22:47:30.042320  3264 net.cpp:198] prelu3 needs backward computation.
I0920 22:47:30.042325  3264 net.cpp:198] conv3 needs backward computation.
I0920 22:47:30.042330  3264 net.cpp:198] pool2 needs backward computation.
I0920 22:47:30.042335  3264 net.cpp:198] prelu2 needs backward computation.
I0920 22:47:30.042340  3264 net.cpp:198] conv2 needs backward computation.
I0920 22:47:30.042345  3264 net.cpp:198] pool1 needs backward computation.
I0920 22:47:30.042348  3264 net.cpp:198] prelu1 needs backward computation.
I0920 22:47:30.042353  3264 net.cpp:198] conv1 needs backward computation.
I0920 22:47:30.042359  3264 net.cpp:200] label_PyData_1_split does not need backward computation.
I0920 22:47:30.042367  3264 net.cpp:200] PyData does not need backward computation.
I0920 22:47:30.042373  3264 net.cpp:242] This network produces output bbox_loss
I0920 22:47:30.042379  3264 net.cpp:242] This network produces output cls_Acc
I0920 22:47:30.042384  3264 net.cpp:242] This network produces output cls_loss
I0920 22:47:30.042389  3264 net.cpp:242] This network produces output landmark_loss
I0920 22:47:30.042434  3264 net.cpp:255] Network initialization done.
I0920 22:47:30.042579  3264 solver.cpp:57] Solver scaffolding done.
I0920 22:47:30.042695  3264 caffe.cpp:242] Starting Optimization
I0920 22:47:30.042701  3264 solver.cpp:289] Solving ONet
I0920 22:47:30.042704  3264 solver.cpp:290] Learning Rate Policy: step
I0920 22:47:36.044335  3264 solver.cpp:239] Iteration 0 (-2.34091e+15 iter/s, 6.001s/200 iters), loss = 2.74589
I0920 22:47:36.044369  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.121751 (* 0.5 = 0.0608756 loss)
I0920 22:47:36.044379  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.543379
I0920 22:47:36.044400  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.675722 (* 1 = 0.675722 loss)
I0920 22:47:36.044407  3264 solver.cpp:258]     Train net output #3: landmark_loss = 2.00929 (* 1 = 2.00929 loss)
I0920 22:47:36.044428  3264 sgd_solver.cpp:112] Iteration 0, lr = 0.01
I0920 23:03:32.679822  3264 solver.cpp:239] Iteration 200 (0.209066 iter/s, 956.635s/200 iters), loss = 0.241223
I0920 23:03:32.687785  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0521567 (* 0.5 = 0.0260784 loss)
I0920 23:03:32.687809  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.926941
I0920 23:03:32.687815  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.183698 (* 1 = 0.183698 loss)
I0920 23:03:32.687834  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0314462 (* 1 = 0.0314462 loss)
I0920 23:03:32.687857  3264 sgd_solver.cpp:112] Iteration 200, lr = 0.01
I0920 23:19:32.709398  3264 solver.cpp:239] Iteration 400 (0.208329 iter/s, 960.021s/200 iters), loss = 0.421696
I0920 23:19:32.720113  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0306898 (* 0.5 = 0.0153449 loss)
I0920 23:19:32.720121  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.840183
I0920 23:19:32.720129  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.380352 (* 1 = 0.380352 loss)
I0920 23:19:32.720134  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0259994 (* 1 = 0.0259994 loss)
I0920 23:19:32.720175  3264 sgd_solver.cpp:112] Iteration 400, lr = 0.01
I0920 23:35:34.400674  3264 solver.cpp:239] Iteration 600 (0.207969 iter/s, 961.68s/200 iters), loss = 0.0763306
I0920 23:35:34.400812  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0604052 (* 0.5 = 0.0302026 loss)
I0920 23:35:34.400820  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.990868
I0920 23:35:34.400826  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0273144 (* 1 = 0.0273144 loss)
I0920 23:35:34.400831  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0188136 (* 1 = 0.0188136 loss)
I0920 23:35:34.400838  3264 sgd_solver.cpp:112] Iteration 600, lr = 0.01
I0920 23:51:38.511201  3264 solver.cpp:239] Iteration 800 (0.207445 iter/s, 964.11s/200 iters), loss = 0.195329
I0920 23:51:38.511299  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.026655 (* 0.5 = 0.0133275 loss)
I0920 23:51:38.511307  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.926941
I0920 23:51:38.511312  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.157027 (* 1 = 0.157027 loss)
I0920 23:51:38.511317  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0249742 (* 1 = 0.0249742 loss)
I0920 23:51:38.511325  3264 sgd_solver.cpp:112] Iteration 800, lr = 0.01
I0921 00:07:39.916055  3264 solver.cpp:239] Iteration 1000 (0.208029 iter/s, 961.404s/200 iters), loss = 0.362497
I0921 00:07:39.916183  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0482215 (* 0.5 = 0.0241108 loss)
I0921 00:07:39.916190  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.840183
I0921 00:07:39.916196  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.319387 (* 1 = 0.319387 loss)
I0921 00:07:39.916201  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0189985 (* 1 = 0.0189985 loss)
I0921 00:07:39.916209  3264 sgd_solver.cpp:112] Iteration 1000, lr = 0.01
I0921 00:23:44.312402  3264 solver.cpp:239] Iteration 1200 (0.207384 iter/s, 964.396s/200 iters), loss = 0.173708
I0921 00:23:44.312541  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0286476 (* 0.5 = 0.0143238 loss)
I0921 00:23:44.312562  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.940639
I0921 00:23:44.312567  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.139829 (* 1 = 0.139829 loss)
I0921 00:23:44.312572  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0195553 (* 1 = 0.0195553 loss)
I0921 00:23:44.312595  3264 sgd_solver.cpp:112] Iteration 1200, lr = 0.01
I0921 00:39:50.515043  3264 solver.cpp:239] Iteration 1400 (0.206996 iter/s, 966.202s/200 iters), loss = 0.127678
I0921 00:39:50.515221  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.039852 (* 0.5 = 0.019926 loss)
I0921 00:39:50.515244  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.977169
I0921 00:39:50.515250  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0805347 (* 1 = 0.0805347 loss)
I0921 00:39:50.515256  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0272172 (* 1 = 0.0272172 loss)
I0921 00:39:50.515264  3264 sgd_solver.cpp:112] Iteration 1400, lr = 0.01
I0921 00:55:52.884893  3264 solver.cpp:239] Iteration 1600 (0.20782 iter/s, 962.369s/200 iters), loss = 0.269236
I0921 00:55:52.899621  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0334827 (* 0.5 = 0.0167413 loss)
I0921 00:55:52.899629  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.917808
I0921 00:55:52.899636  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.231412 (* 1 = 0.231412 loss)
I0921 00:55:52.899642  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0210827 (* 1 = 0.0210827 loss)
I0921 00:55:52.899667  3264 sgd_solver.cpp:112] Iteration 1600, lr = 0.01
I0921 01:11:55.008936  3264 solver.cpp:239] Iteration 1800 (0.207877 iter/s, 962.109s/200 iters), loss = 0.169446
I0921 01:11:55.009095  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0415606 (* 0.5 = 0.0207803 loss)
I0921 01:11:55.009101  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.949772
I0921 01:11:55.009122  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.136708 (* 1 = 0.136708 loss)
I0921 01:11:55.009130  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0119579 (* 1 = 0.0119579 loss)
I0921 01:11:55.009153  3264 sgd_solver.cpp:112] Iteration 1800, lr = 0.01
I0921 01:27:57.077783  3264 solver.cpp:239] Iteration 2000 (0.207886 iter/s, 962.068s/200 iters), loss = 0.229917
I0921 01:27:57.077888  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0209154 (* 0.5 = 0.0104577 loss)
I0921 01:27:57.077895  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.940639
I0921 01:27:57.077901  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.206283 (* 1 = 0.206283 loss)
I0921 01:27:57.077905  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0131762 (* 1 = 0.0131762 loss)
I0921 01:27:57.077917  3264 sgd_solver.cpp:112] Iteration 2000, lr = 0.01
I0921 01:44:02.053169  3264 solver.cpp:239] Iteration 2200 (0.207259 iter/s, 964.975s/200 iters), loss = 0.249424
I0921 01:44:02.053272  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0333722 (* 0.5 = 0.0166861 loss)
I0921 01:44:02.053293  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.917808
I0921 01:44:02.053300  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.217956 (* 1 = 0.217956 loss)
I0921 01:44:02.053306  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.014782 (* 1 = 0.014782 loss)
I0921 01:44:02.053328  3264 sgd_solver.cpp:112] Iteration 2200, lr = 0.01
I0921 02:00:04.307153  3264 solver.cpp:239] Iteration 2400 (0.207846 iter/s, 962.253s/200 iters), loss = 0.222
I0921 02:00:04.307277  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0379264 (* 0.5 = 0.0189632 loss)
I0921 02:00:04.307301  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.940639
I0921 02:00:04.307322  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.187347 (* 1 = 0.187347 loss)
I0921 02:00:04.307327  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0156905 (* 1 = 0.0156905 loss)
I0921 02:00:04.307334  3264 sgd_solver.cpp:112] Iteration 2400, lr = 0.01
I0921 02:16:05.774715  3264 solver.cpp:239] Iteration 2600 (0.208015 iter/s, 961.467s/200 iters), loss = 0.119345
I0921 02:16:05.774837  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0333044 (* 0.5 = 0.0166522 loss)
I0921 02:16:05.774845  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.977169
I0921 02:16:05.774850  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.079065 (* 1 = 0.079065 loss)
I0921 02:16:05.774857  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0236282 (* 1 = 0.0236282 loss)
I0921 02:16:05.774863  3264 sgd_solver.cpp:112] Iteration 2600, lr = 0.01
I0921 02:32:06.269835  3264 solver.cpp:239] Iteration 2800 (0.208226 iter/s, 960.494s/200 iters), loss = 0.295041
I0921 02:32:06.269984  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0276629 (* 0.5 = 0.0138315 loss)
I0921 02:32:06.269991  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.894977
I0921 02:32:06.269997  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.269468 (* 1 = 0.269468 loss)
I0921 02:32:06.270002  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0117423 (* 1 = 0.0117423 loss)
I0921 02:32:06.270009  3264 sgd_solver.cpp:112] Iteration 2800, lr = 0.01
I0921 02:48:07.535812  3264 solver.cpp:239] Iteration 3000 (0.208059 iter/s, 961.265s/200 iters), loss = 0.0870598
I0921 02:48:07.548250  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.032728 (* 0.5 = 0.016364 loss)
I0921 02:48:07.548259  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.977169
I0921 02:48:07.548264  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0588869 (* 1 = 0.0588869 loss)
I0921 02:48:07.548272  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0118093 (* 1 = 0.0118093 loss)
I0921 02:48:07.548283  3264 sgd_solver.cpp:112] Iteration 3000, lr = 0.01
I0921 03:04:07.843083  3264 solver.cpp:239] Iteration 3200 (0.20827 iter/s, 960.294s/200 iters), loss = 0.278615
I0921 03:04:07.843219  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0286269 (* 0.5 = 0.0143134 loss)
I0921 03:04:07.843226  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.908676
I0921 03:04:07.843231  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.235479 (* 1 = 0.235479 loss)
I0921 03:04:07.843237  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0288233 (* 1 = 0.0288233 loss)
I0921 03:04:07.843245  3264 sgd_solver.cpp:112] Iteration 3200, lr = 0.01
I0921 03:20:10.708935  3264 solver.cpp:239] Iteration 3400 (0.207713 iter/s, 962.865s/200 iters), loss = 0.125417
I0921 03:20:10.709077  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0368404 (* 0.5 = 0.0184202 loss)
I0921 03:20:10.709084  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.96347
I0921 03:20:10.709091  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0960765 (* 1 = 0.0960765 loss)
I0921 03:20:10.709097  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0109202 (* 1 = 0.0109202 loss)
I0921 03:20:10.709105  3264 sgd_solver.cpp:112] Iteration 3400, lr = 0.01
I0921 03:36:11.931502  3264 solver.cpp:239] Iteration 3600 (0.208068 iter/s, 961.222s/200 iters), loss = 0.102863
I0921 03:36:11.931610  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0210856 (* 0.5 = 0.0105428 loss)
I0921 03:36:11.931630  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.972603
I0921 03:36:11.931650  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0788178 (* 1 = 0.0788178 loss)
I0921 03:36:11.931669  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0135026 (* 1 = 0.0135026 loss)
I0921 03:36:11.931695  3264 sgd_solver.cpp:112] Iteration 3600, lr = 0.01
I0921 03:52:13.292440  3264 solver.cpp:239] Iteration 3800 (0.208039 iter/s, 961.36s/200 iters), loss = 0.110647
I0921 03:52:13.292542  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0332234 (* 0.5 = 0.0166117 loss)
I0921 03:52:13.292548  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.96347
I0921 03:52:13.292554  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0823576 (* 1 = 0.0823576 loss)
I0921 03:52:13.292560  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.011678 (* 1 = 0.011678 loss)
I0921 03:52:13.292568  3264 sgd_solver.cpp:112] Iteration 3800, lr = 0.01
I0921 04:08:14.194298  3264 solver.cpp:239] Iteration 4000 (0.208138 iter/s, 960.901s/200 iters), loss = 0.219543
I0921 04:08:14.194420  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.020644 (* 0.5 = 0.010322 loss)
I0921 04:08:14.194427  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.908676
I0921 04:08:14.194433  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.196153 (* 1 = 0.196153 loss)
I0921 04:08:14.194437  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0130679 (* 1 = 0.0130679 loss)
I0921 04:08:14.194445  3264 sgd_solver.cpp:112] Iteration 4000, lr = 0.01
I0921 04:24:15.078661  3264 solver.cpp:239] Iteration 4200 (0.208142 iter/s, 960.884s/200 iters), loss = 0.154065
I0921 04:24:15.078826  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0335193 (* 0.5 = 0.0167597 loss)
I0921 04:24:15.078835  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.949772
I0921 04:24:15.078855  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.122105 (* 1 = 0.122105 loss)
I0921 04:24:15.078876  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0152007 (* 1 = 0.0152007 loss)
I0921 04:24:15.078898  3264 sgd_solver.cpp:112] Iteration 4200, lr = 0.01
I0921 04:40:15.496052  3264 solver.cpp:239] Iteration 4400 (0.208243 iter/s, 960.417s/200 iters), loss = 0.144078
I0921 04:40:15.509601  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0429596 (* 0.5 = 0.0214798 loss)
I0921 04:40:15.509611  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.954338
I0921 04:40:15.509620  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.108122 (* 1 = 0.108122 loss)
I0921 04:40:15.509629  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0144764 (* 1 = 0.0144764 loss)
I0921 04:40:15.509639  3264 sgd_solver.cpp:112] Iteration 4400, lr = 0.01
I0921 04:56:15.868373  3264 solver.cpp:239] Iteration 4600 (0.208256 iter/s, 960.358s/200 iters), loss = 0.235048
I0921 04:56:15.879143  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0453521 (* 0.5 = 0.022676 loss)
I0921 04:56:15.879151  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.940639
I0921 04:56:15.879158  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.19561 (* 1 = 0.19561 loss)
I0921 04:56:15.879164  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.016762 (* 1 = 0.016762 loss)
I0921 04:56:15.879186  3264 sgd_solver.cpp:112] Iteration 4600, lr = 0.01
I0921 05:12:15.963493  3264 solver.cpp:239] Iteration 4800 (0.208315 iter/s, 960.084s/200 iters), loss = 0.0880727
I0921 05:12:15.972419  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0310375 (* 0.5 = 0.0155188 loss)
I0921 05:12:15.972427  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.981735
I0921 05:12:15.972436  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0564189 (* 1 = 0.0564189 loss)
I0921 05:12:15.972442  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0161355 (* 1 = 0.0161355 loss)
I0921 05:12:15.972465  3264 sgd_solver.cpp:112] Iteration 4800, lr = 0.01
I0921 05:28:15.720120  3264 solver.cpp:239] Iteration 5000 (0.208388 iter/s, 959.747s/200 iters), loss = 0.139138
I0921 05:28:15.733192  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0282161 (* 0.5 = 0.0141081 loss)
I0921 05:28:15.733203  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.954338
I0921 05:28:15.733211  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0960158 (* 1 = 0.0960158 loss)
I0921 05:28:15.733217  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.029015 (* 1 = 0.029015 loss)
I0921 05:28:15.733225  3264 sgd_solver.cpp:112] Iteration 5000, lr = 0.01
I0921 05:44:16.077662  3264 solver.cpp:239] Iteration 5200 (0.208259 iter/s, 960.344s/200 iters), loss = 0.123187
I0921 05:44:16.077764  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0354688 (* 0.5 = 0.0177344 loss)
I0921 05:44:16.077770  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.958904
I0921 05:44:16.077775  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0916418 (* 1 = 0.0916418 loss)
I0921 05:44:16.077780  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.013811 (* 1 = 0.013811 loss)
I0921 05:44:16.077788  3264 sgd_solver.cpp:112] Iteration 5200, lr = 0.01
I0921 06:00:17.914960  3264 solver.cpp:239] Iteration 5400 (0.207935 iter/s, 961.837s/200 iters), loss = 0.211903
I0921 06:00:17.915118  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0297531 (* 0.5 = 0.0148766 loss)
I0921 06:00:17.915125  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.926941
I0921 06:00:17.915130  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.185468 (* 1 = 0.185468 loss)
I0921 06:00:17.915136  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0115587 (* 1 = 0.0115587 loss)
I0921 06:00:17.915145  3264 sgd_solver.cpp:112] Iteration 5400, lr = 0.01
I0921 06:16:23.014591  3264 solver.cpp:239] Iteration 5600 (0.207233 iter/s, 965.099s/200 iters), loss = 0.294196
I0921 06:16:23.023188  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0314611 (* 0.5 = 0.0157305 loss)
I0921 06:16:23.023198  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.890411
I0921 06:16:23.023207  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.267991 (* 1 = 0.267991 loss)
I0921 06:16:23.023214  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0104746 (* 1 = 0.0104746 loss)
I0921 06:16:23.023224  3264 sgd_solver.cpp:112] Iteration 5600, lr = 0.01
I0921 06:32:23.283491  3264 solver.cpp:239] Iteration 5800 (0.208277 iter/s, 960.26s/200 iters), loss = 0.22422
I0921 06:32:23.291909  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0265108 (* 0.5 = 0.0132554 loss)
I0921 06:32:23.291916  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.917808
I0921 06:32:23.291924  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.19215 (* 1 = 0.19215 loss)
I0921 06:32:23.291930  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0188154 (* 1 = 0.0188154 loss)
I0921 06:32:23.291952  3264 sgd_solver.cpp:112] Iteration 5800, lr = 0.01
I0921 06:48:23.487090  3264 solver.cpp:239] Iteration 6000 (0.208291 iter/s, 960.195s/200 iters), loss = 0.113178
I0921 06:48:23.496773  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0205782 (* 0.5 = 0.0102891 loss)
I0921 06:48:23.496781  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.986301
I0921 06:48:23.496788  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0884546 (* 1 = 0.0884546 loss)
I0921 06:48:23.496794  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0144353 (* 1 = 0.0144353 loss)
I0921 06:48:23.496803  3264 sgd_solver.cpp:112] Iteration 6000, lr = 0.01
I0921 07:04:22.921651  3264 solver.cpp:239] Iteration 6200 (0.208458 iter/s, 959.424s/200 iters), loss = 0.106407
I0921 07:04:22.933611  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0195984 (* 0.5 = 0.0097992 loss)
I0921 07:04:22.933620  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.968037
I0921 07:04:22.933626  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0793744 (* 1 = 0.0793744 loss)
I0921 07:04:22.933632  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0172343 (* 1 = 0.0172343 loss)
I0921 07:04:22.933641  3264 sgd_solver.cpp:112] Iteration 6200, lr = 0.01
I0921 07:20:24.957007  3264 solver.cpp:239] Iteration 6400 (0.207895 iter/s, 962.023s/200 iters), loss = 0.0747969
I0921 07:20:24.970201  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0388893 (* 0.5 = 0.0194447 loss)
I0921 07:20:24.970209  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.986301
I0921 07:20:24.970217  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.042798 (* 1 = 0.042798 loss)
I0921 07:20:24.970223  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0125547 (* 1 = 0.0125547 loss)
I0921 07:20:24.970247  3264 sgd_solver.cpp:112] Iteration 6400, lr = 0.01
I0921 07:36:28.248363  3264 solver.cpp:239] Iteration 6600 (0.207624 iter/s, 963.278s/200 iters), loss = 0.311322
I0921 07:36:28.258679  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0398272 (* 0.5 = 0.0199136 loss)
I0921 07:36:28.258687  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.885845
I0921 07:36:28.258694  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.276382 (* 1 = 0.276382 loss)
I0921 07:36:28.258700  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0150276 (* 1 = 0.0150276 loss)
I0921 07:36:28.258709  3264 sgd_solver.cpp:112] Iteration 6600, lr = 0.01
I0921 07:52:28.976471  3264 solver.cpp:239] Iteration 6800 (0.208178 iter/s, 960.717s/200 iters), loss = 0.131484
I0921 07:52:28.990824  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0241404 (* 0.5 = 0.0120702 loss)
I0921 07:52:28.990833  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.96347
I0921 07:52:28.990839  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.108994 (* 1 = 0.108994 loss)
I0921 07:52:28.990844  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0104205 (* 1 = 0.0104205 loss)
I0921 07:52:28.990850  3264 sgd_solver.cpp:112] Iteration 6800, lr = 0.01
I0921 08:08:30.990557  3264 solver.cpp:239] Iteration 7000 (0.2079 iter/s, 961.999s/200 iters), loss = 0.151937
I0921 08:08:31.001559  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0419048 (* 0.5 = 0.0209524 loss)
I0921 08:08:31.001566  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.958904
I0921 08:08:31.001574  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.121009 (* 1 = 0.121009 loss)
I0921 08:08:31.001583  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.00997668 (* 1 = 0.00997668 loss)
I0921 08:08:31.001593  3264 sgd_solver.cpp:112] Iteration 7000, lr = 0.01
I0921 08:24:33.265193  3264 solver.cpp:239] Iteration 7200 (0.207843 iter/s, 962.263s/200 iters), loss = 0.300401
I0921 08:24:33.265318  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0398993 (* 0.5 = 0.0199497 loss)
I0921 08:24:33.265326  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.885845
I0921 08:24:33.265331  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.267912 (* 1 = 0.267912 loss)
I0921 08:24:33.265336  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.01254 (* 1 = 0.01254 loss)
I0921 08:24:33.265344  3264 sgd_solver.cpp:112] Iteration 7200, lr = 0.01
I0921 08:40:34.079684  3264 solver.cpp:239] Iteration 7400 (0.208157 iter/s, 960.814s/200 iters), loss = 0.12345
I0921 08:40:34.079811  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0306251 (* 0.5 = 0.0153126 loss)
I0921 08:40:34.079818  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.972603
I0921 08:40:34.079823  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0998874 (* 1 = 0.0998874 loss)
I0921 08:40:34.079829  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.00825038 (* 1 = 0.00825038 loss)
I0921 08:40:34.079836  3264 sgd_solver.cpp:112] Iteration 7400, lr = 0.01
I0921 08:56:34.377512  3264 solver.cpp:239] Iteration 7600 (0.208269 iter/s, 960.297s/200 iters), loss = 0.15667
I0921 08:56:34.377657  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0205912 (* 0.5 = 0.0102956 loss)
I0921 08:56:34.377665  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.949772
I0921 08:56:34.377674  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.136815 (* 1 = 0.136815 loss)
I0921 08:56:34.377696  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.00956001 (* 1 = 0.00956001 loss)
I0921 08:56:34.377705  3264 sgd_solver.cpp:112] Iteration 7600, lr = 0.01
I0921 09:12:42.483697  3264 solver.cpp:239] Iteration 7800 (0.206589 iter/s, 968.106s/200 iters), loss = 0.124364
I0921 09:12:42.483816  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0397837 (* 0.5 = 0.0198919 loss)
I0921 09:12:42.483824  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.96347
I0921 09:12:42.483829  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0945398 (* 1 = 0.0945398 loss)
I0921 09:12:42.483836  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.00993303 (* 1 = 0.00993303 loss)
I0921 09:12:42.483845  3264 sgd_solver.cpp:112] Iteration 7800, lr = 0.01
I0921 09:29:20.701190  3264 solver.cpp:239] Iteration 8000 (0.200357 iter/s, 998.217s/200 iters), loss = 0.142765
I0921 09:29:20.717367  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0328592 (* 0.5 = 0.0164296 loss)
I0921 09:29:20.717377  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.96347
I0921 09:29:20.717387  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.112801 (* 1 = 0.112801 loss)
I0921 09:29:20.717409  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0135349 (* 1 = 0.0135349 loss)
I0921 09:29:20.717433  3264 sgd_solver.cpp:112] Iteration 8000, lr = 0.01
I0921 09:45:13.149353  3264 solver.cpp:239] Iteration 8200 (0.209989 iter/s, 952.431s/200 iters), loss = 0.0977293
I0921 09:45:13.158850  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.04368 (* 0.5 = 0.02184 loss)
I0921 09:45:13.158856  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.986301
I0921 09:45:13.158861  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0614254 (* 1 = 0.0614254 loss)
I0921 09:45:13.158869  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0144643 (* 1 = 0.0144643 loss)
I0921 09:45:13.158876  3264 sgd_solver.cpp:112] Iteration 8200, lr = 0.01
I0921 10:01:05.250639  3264 solver.cpp:239] Iteration 8400 (0.210064 iter/s, 952.091s/200 iters), loss = 0.0784108
I0921 10:01:05.250793  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0275281 (* 0.5 = 0.013764 loss)
I0921 10:01:05.250802  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.995434
I0921 10:01:05.250821  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0421792 (* 1 = 0.0421792 loss)
I0921 10:01:05.250839  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.022468 (* 1 = 0.022468 loss)
I0921 10:01:05.250847  3264 sgd_solver.cpp:112] Iteration 8400, lr = 0.01
I0921 10:17:00.793982  3264 solver.cpp:239] Iteration 8600 (0.209305 iter/s, 955.543s/200 iters), loss = 0.105717
I0921 10:17:00.805428  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0179049 (* 0.5 = 0.00895247 loss)
I0921 10:17:00.805438  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.968037
I0921 10:17:00.805446  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0863626 (* 1 = 0.0863626 loss)
I0921 10:17:00.805454  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0104025 (* 1 = 0.0104025 loss)
I0921 10:17:00.805464  3264 sgd_solver.cpp:112] Iteration 8600, lr = 0.01
I0921 10:32:52.840044  3264 solver.cpp:239] Iteration 8800 (0.210077 iter/s, 952.034s/200 iters), loss = 0.432505
I0921 10:32:52.846933  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0450531 (* 0.5 = 0.0225266 loss)
I0921 10:32:52.846941  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.885845
I0921 10:32:52.846948  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.396348 (* 1 = 0.396348 loss)
I0921 10:32:52.846953  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0136319 (* 1 = 0.0136319 loss)
I0921 10:32:52.846976  3264 sgd_solver.cpp:112] Iteration 8800, lr = 0.01
I0921 10:48:59.624279  3264 solver.cpp:239] Iteration 9000 (0.206873 iter/s, 966.777s/200 iters), loss = 0.182621
I0921 10:48:59.624418  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0329079 (* 0.5 = 0.016454 loss)
I0921 10:48:59.624438  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.931507
I0921 10:48:59.624446  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.156937 (* 1 = 0.156937 loss)
I0921 10:48:59.624452  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.00923048 (* 1 = 0.00923048 loss)
I0921 10:48:59.624475  3264 sgd_solver.cpp:112] Iteration 9000, lr = 0.01
I0921 11:05:17.306479  3264 solver.cpp:239] Iteration 9200 (0.204565 iter/s, 977.682s/200 iters), loss = 0.143628
I0921 11:05:17.306617  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0308317 (* 0.5 = 0.0154159 loss)
I0921 11:05:17.306643  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.958904
I0921 11:05:17.306649  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.106702 (* 1 = 0.106702 loss)
I0921 11:05:17.306654  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0215105 (* 1 = 0.0215105 loss)
I0921 11:05:17.306663  3264 sgd_solver.cpp:112] Iteration 9200, lr = 0.01
I0921 11:21:10.100414  3264 solver.cpp:239] Iteration 9400 (0.209909 iter/s, 952.793s/200 iters), loss = 0.116688
I0921 11:21:10.100565  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0361834 (* 0.5 = 0.0180917 loss)
I0921 11:21:10.100571  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.986301
I0921 11:21:10.100579  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0850141 (* 1 = 0.0850141 loss)
I0921 11:21:10.100584  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0135826 (* 1 = 0.0135826 loss)
I0921 11:21:10.100607  3264 sgd_solver.cpp:112] Iteration 9400, lr = 0.01
I0921 11:37:15.097792  3264 solver.cpp:239] Iteration 9600 (0.207255 iter/s, 964.997s/200 iters), loss = 0.0640607
I0921 11:37:15.106329  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0378692 (* 0.5 = 0.0189346 loss)
I0921 11:37:15.106338  3264 solver.cpp:258]     Train net output #1: cls_Acc = 1
I0921 11:37:15.106345  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0248973 (* 1 = 0.0248973 loss)
I0921 11:37:15.106353  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0202293 (* 1 = 0.0202293 loss)
I0921 11:37:15.106364  3264 sgd_solver.cpp:112] Iteration 9600, lr = 0.01
I0921 11:53:17.322468  3264 solver.cpp:239] Iteration 9800 (0.207854 iter/s, 962.216s/200 iters), loss = 0.0833072
I0921 11:53:17.330484  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0361312 (* 0.5 = 0.0180656 loss)
I0921 11:53:17.330492  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.981735
I0921 11:53:17.330497  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0514855 (* 1 = 0.0514855 loss)
I0921 11:53:17.330503  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0137566 (* 1 = 0.0137566 loss)
I0921 11:53:17.330512  3264 sgd_solver.cpp:112] Iteration 9800, lr = 0.01
I0921 12:09:10.155871  3264 solver.cpp:464] Snapshotting to binary proto file ../tmp/model/onet/0920/solver_iter_10000.caffemodel
I0921 12:09:10.164399  3264 net.cpp:842] Serializing 27 layers
I0921 12:09:10.437899  3264 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ../tmp/model/onet/0920/solver_iter_10000.solverstate
I0921 12:09:15.206321  3264 solver.cpp:239] Iteration 10000 (0.208796 iter/s, 957.875s/200 iters), loss = 0.0803065
I0921 12:09:15.206349  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0270498 (* 0.5 = 0.0135249 loss)
I0921 12:09:15.206369  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.981735
I0921 12:09:15.206377  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0513443 (* 1 = 0.0513443 loss)
I0921 12:09:15.206395  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0154378 (* 1 = 0.0154378 loss)
I0921 12:09:15.206418  3264 sgd_solver.cpp:112] Iteration 10000, lr = 0.01
I0921 12:25:05.858714  3264 solver.cpp:239] Iteration 10200 (0.210382 iter/s, 950.652s/200 iters), loss = 0.10032
I0921 12:25:05.866909  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0314626 (* 0.5 = 0.0157313 loss)
I0921 12:25:05.866916  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.981735
I0921 12:25:05.866925  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0723488 (* 1 = 0.0723488 loss)
I0921 12:25:05.866930  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0122401 (* 1 = 0.0122401 loss)
I0921 12:25:05.866955  3264 sgd_solver.cpp:112] Iteration 10200, lr = 0.01
I0921 12:40:56.593158  3264 solver.cpp:239] Iteration 10400 (0.210366 iter/s, 950.726s/200 iters), loss = 0.096254
I0921 12:40:56.605522  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0268352 (* 0.5 = 0.0134176 loss)
I0921 12:40:56.605530  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.977169
I0921 12:40:56.605537  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0758393 (* 1 = 0.0758393 loss)
I0921 12:40:56.605543  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.00699752 (* 1 = 0.00699752 loss)
I0921 12:40:56.605566  3264 sgd_solver.cpp:112] Iteration 10400, lr = 0.01
I0921 12:56:48.098836  3264 solver.cpp:239] Iteration 10600 (0.210196 iter/s, 951.493s/200 iters), loss = 0.0396037
I0921 12:56:48.098966  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.00826324 (* 0.5 = 0.00413162 loss)
I0921 12:56:48.098974  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.995434
I0921 12:56:48.098984  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0273162 (* 1 = 0.0273162 loss)
I0921 12:56:48.098990  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.00815631 (* 1 = 0.00815631 loss)
I0921 12:56:48.099001  3264 sgd_solver.cpp:112] Iteration 10600, lr = 0.01
I0921 13:12:39.212442  3264 solver.cpp:239] Iteration 10800 (0.21028 iter/s, 951.113s/200 iters), loss = 0.0860766
I0921 13:12:39.226984  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0279567 (* 0.5 = 0.0139783 loss)
I0921 13:12:39.226992  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.990868
I0921 13:12:39.227001  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0543892 (* 1 = 0.0543892 loss)
I0921 13:12:39.227007  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0177095 (* 1 = 0.0177095 loss)
I0921 13:12:39.227016  3264 sgd_solver.cpp:112] Iteration 10800, lr = 0.01
I0921 13:28:31.503350  3264 solver.cpp:239] Iteration 11000 (0.210023 iter/s, 952.276s/200 iters), loss = 0.192046
I0921 13:28:31.503489  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0346397 (* 0.5 = 0.0173198 loss)
I0921 13:28:31.503511  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.940639
I0921 13:28:31.503518  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.15611 (* 1 = 0.15611 loss)
I0921 13:28:31.503523  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0186169 (* 1 = 0.0186169 loss)
I0921 13:28:31.503546  3264 sgd_solver.cpp:112] Iteration 11000, lr = 0.01
I0921 13:44:24.954609  3264 solver.cpp:239] Iteration 11200 (0.209764 iter/s, 953.451s/200 iters), loss = 0.116596
I0921 13:44:24.963289  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0268204 (* 0.5 = 0.0134102 loss)
I0921 13:44:24.963296  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.968037
I0921 13:44:24.963306  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0927546 (* 1 = 0.0927546 loss)
I0921 13:44:24.963315  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0104312 (* 1 = 0.0104312 loss)
I0921 13:44:24.963325  3264 sgd_solver.cpp:112] Iteration 11200, lr = 0.01
I0921 14:00:16.925050  3264 solver.cpp:239] Iteration 11400 (0.210093 iter/s, 951.961s/200 iters), loss = 0.0724666
I0921 14:00:16.937677  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0308822 (* 0.5 = 0.0154411 loss)
I0921 14:00:16.937686  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.986301
I0921 14:00:16.937693  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0437593 (* 1 = 0.0437593 loss)
I0921 14:00:16.937716  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0132666 (* 1 = 0.0132666 loss)
I0921 14:00:16.937736  3264 sgd_solver.cpp:112] Iteration 11400, lr = 0.01
I0921 14:16:10.970185  3264 solver.cpp:239] Iteration 11600 (0.209637 iter/s, 954.032s/200 iters), loss = 0.0392553
I0921 14:16:10.970325  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0270646 (* 0.5 = 0.0135323 loss)
I0921 14:16:10.970332  3264 solver.cpp:258]     Train net output #1: cls_Acc = 1
I0921 14:16:10.970352  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0140014 (* 1 = 0.0140014 loss)
I0921 14:16:10.970357  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.011722 (* 1 = 0.011722 loss)
I0921 14:16:10.970378  3264 sgd_solver.cpp:112] Iteration 11600, lr = 0.01
I0921 14:32:04.781755  3264 solver.cpp:239] Iteration 11800 (0.209685 iter/s, 953.811s/200 iters), loss = 0.103753
I0921 14:32:04.797670  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0364078 (* 0.5 = 0.0182039 loss)
I0921 14:32:04.797679  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.981735
I0921 14:32:04.797685  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0701899 (* 1 = 0.0701899 loss)
I0921 14:32:04.797690  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0153598 (* 1 = 0.0153598 loss)
I0921 14:32:04.797699  3264 sgd_solver.cpp:112] Iteration 11800, lr = 0.01
I0921 14:48:39.395717  3264 solver.cpp:239] Iteration 12000 (0.201086 iter/s, 994.598s/200 iters), loss = 0.120285
I0921 14:48:39.410763  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0271612 (* 0.5 = 0.0135806 loss)
I0921 14:48:39.410770  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.986301
I0921 14:48:39.410792  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0935456 (* 1 = 0.0935456 loss)
I0921 14:48:39.410815  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0131591 (* 1 = 0.0131591 loss)
I0921 14:48:39.410825  3264 sgd_solver.cpp:112] Iteration 12000, lr = 0.01
I0921 15:04:33.321101  3264 solver.cpp:239] Iteration 12200 (0.209663 iter/s, 953.91s/200 iters), loss = 0.210304
I0921 15:04:33.329165  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0476251 (* 0.5 = 0.0238126 loss)
I0921 15:04:33.329174  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.936073
I0921 15:04:33.329180  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.175343 (* 1 = 0.175343 loss)
I0921 15:04:33.329185  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0111492 (* 1 = 0.0111492 loss)
I0921 15:04:33.329195  3264 sgd_solver.cpp:112] Iteration 12200, lr = 0.01
I0921 15:20:35.729576  3264 solver.cpp:239] Iteration 12400 (0.207814 iter/s, 962.4s/200 iters), loss = 0.613652
I0921 15:20:35.743980  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0316837 (* 0.5 = 0.0158418 loss)
I0921 15:20:35.743989  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.849315
I0921 15:20:35.743999  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.589476 (* 1 = 0.589476 loss)
I0921 15:20:35.744007  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.00833507 (* 1 = 0.00833507 loss)
I0921 15:20:35.744017  3264 sgd_solver.cpp:112] Iteration 12400, lr = 0.01
I0921 15:36:39.483278  3264 solver.cpp:239] Iteration 12600 (0.207525 iter/s, 963.739s/200 iters), loss = 0.329612
I0921 15:36:39.483366  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0251778 (* 0.5 = 0.0125889 loss)
I0921 15:36:39.483386  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.876712
I0921 15:36:39.483405  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.305435 (* 1 = 0.305435 loss)
I0921 15:36:39.483412  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.011588 (* 1 = 0.011588 loss)
I0921 15:36:39.483433  3264 sgd_solver.cpp:112] Iteration 12600, lr = 0.01
I0921 15:52:35.272826  3264 solver.cpp:239] Iteration 12800 (0.209251 iter/s, 955.789s/200 iters), loss = 0.187189
I0921 15:52:35.286335  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.019275 (* 0.5 = 0.00963748 loss)
I0921 15:52:35.286345  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.931507
I0921 15:52:35.286353  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.157539 (* 1 = 0.157539 loss)
I0921 15:52:35.286361  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.020013 (* 1 = 0.020013 loss)
I0921 15:52:35.286371  3264 sgd_solver.cpp:112] Iteration 12800, lr = 0.01
I0921 16:08:26.983683  3264 solver.cpp:239] Iteration 13000 (0.210151 iter/s, 951.697s/200 iters), loss = 0.0659582
I0921 16:08:26.992013  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.026932 (* 0.5 = 0.013466 loss)
I0921 16:08:26.992022  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.986301
I0921 16:08:26.992029  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0385704 (* 1 = 0.0385704 loss)
I0921 16:08:26.992035  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0139222 (* 1 = 0.0139222 loss)
I0921 16:08:26.992058  3264 sgd_solver.cpp:112] Iteration 13000, lr = 0.01
I0921 16:24:18.687075  3264 solver.cpp:239] Iteration 13200 (0.210151 iter/s, 951.695s/200 iters), loss = 0.241296
I0921 16:24:18.687238  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.018406 (* 0.5 = 0.009203 loss)
I0921 16:24:18.687260  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.931507
I0921 16:24:18.687266  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.206778 (* 1 = 0.206778 loss)
I0921 16:24:18.687285  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0253152 (* 1 = 0.0253152 loss)
I0921 16:24:18.687307  3264 sgd_solver.cpp:112] Iteration 13200, lr = 0.01
I0921 16:40:18.945243  3264 solver.cpp:239] Iteration 13400 (0.208277 iter/s, 960.258s/200 iters), loss = 0.143098
I0921 16:40:18.961045  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0339557 (* 0.5 = 0.0169778 loss)
I0921 16:40:18.961055  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.972603
I0921 16:40:18.961061  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.109231 (* 1 = 0.109231 loss)
I0921 16:40:18.961067  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0168893 (* 1 = 0.0168893 loss)
I0921 16:40:18.961091  3264 sgd_solver.cpp:112] Iteration 13400, lr = 0.01
I0921 16:56:18.690755  3264 solver.cpp:239] Iteration 13600 (0.208392 iter/s, 959.729s/200 iters), loss = 0.129552
I0921 16:56:18.704066  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0260277 (* 0.5 = 0.0130138 loss)
I0921 16:56:18.704074  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.954338
I0921 16:56:18.704080  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.109082 (* 1 = 0.109082 loss)
I0921 16:56:18.704087  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.00745633 (* 1 = 0.00745633 loss)
I0921 16:56:18.704097  3264 sgd_solver.cpp:112] Iteration 13600, lr = 0.01
I0921 17:12:26.901368  3264 solver.cpp:239] Iteration 13800 (0.20657 iter/s, 968.197s/200 iters), loss = 0.219872
I0921 17:12:26.901509  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0297399 (* 0.5 = 0.01487 loss)
I0921 17:12:26.901528  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.926941
I0921 17:12:26.901551  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.195667 (* 1 = 0.195667 loss)
I0921 17:12:26.901556  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.00933613 (* 1 = 0.00933613 loss)
I0921 17:12:26.901577  3264 sgd_solver.cpp:112] Iteration 13800, lr = 0.01
I0921 17:28:25.014969  3264 solver.cpp:239] Iteration 14000 (0.208744 iter/s, 958.113s/200 iters), loss = 0.153141
I0921 17:28:25.015107  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.032634 (* 0.5 = 0.016317 loss)
I0921 17:28:25.015115  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.972603
I0921 17:28:25.015134  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.123814 (* 1 = 0.123814 loss)
I0921 17:28:25.015152  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0130104 (* 1 = 0.0130104 loss)
I0921 17:28:25.015175  3264 sgd_solver.cpp:112] Iteration 14000, lr = 0.01
I0921 17:44:15.140341  3264 solver.cpp:239] Iteration 14200 (0.210499 iter/s, 950.125s/200 iters), loss = 0.0964392
I0921 17:44:15.140477  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0238673 (* 0.5 = 0.0119336 loss)
I0921 17:44:15.140486  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.981735
I0921 17:44:15.140506  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0730293 (* 1 = 0.0730293 loss)
I0921 17:44:15.140511  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0114769 (* 1 = 0.0114769 loss)
I0921 17:44:15.140532  3264 sgd_solver.cpp:112] Iteration 14200, lr = 0.01
I0921 18:00:05.176458  3264 solver.cpp:239] Iteration 14400 (0.210519 iter/s, 950.035s/200 iters), loss = 0.189624
I0921 18:00:05.176599  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0251668 (* 0.5 = 0.0125834 loss)
I0921 18:00:05.176621  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.926941
I0921 18:00:05.176630  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.155784 (* 1 = 0.155784 loss)
I0921 18:00:05.176651  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0212571 (* 1 = 0.0212571 loss)
I0921 18:00:05.176673  3264 sgd_solver.cpp:112] Iteration 14400, lr = 0.01
I0921 18:15:57.026906  3264 solver.cpp:239] Iteration 14600 (0.210117 iter/s, 951.85s/200 iters), loss = 0.101163
I0921 18:15:57.027091  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0244469 (* 0.5 = 0.0122235 loss)
I0921 18:15:57.027112  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.972603
I0921 18:15:57.027133  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0800534 (* 1 = 0.0800534 loss)
I0921 18:15:57.027139  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.00888632 (* 1 = 0.00888632 loss)
I0921 18:15:57.027149  3264 sgd_solver.cpp:112] Iteration 14600, lr = 0.01
I0921 18:31:49.391757  3264 solver.cpp:239] Iteration 14800 (0.210004 iter/s, 952.364s/200 iters), loss = 0.120268
I0921 18:31:49.391880  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0325262 (* 0.5 = 0.0162631 loss)
I0921 18:31:49.391886  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.977169
I0921 18:31:49.391906  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0940217 (* 1 = 0.0940217 loss)
I0921 18:31:49.391913  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.00998345 (* 1 = 0.00998345 loss)
I0921 18:31:49.391921  3264 sgd_solver.cpp:112] Iteration 14800, lr = 0.01
I0921 18:47:50.800740  3264 solver.cpp:239] Iteration 15000 (0.208028 iter/s, 961.408s/200 iters), loss = 0.105153
I0921 18:47:50.813045  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0363992 (* 0.5 = 0.0181996 loss)
I0921 18:47:50.813083  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.986301
I0921 18:47:50.813091  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0707589 (* 1 = 0.0707589 loss)
I0921 18:47:50.813113  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0161953 (* 1 = 0.0161953 loss)
I0921 18:47:50.813136  3264 sgd_solver.cpp:112] Iteration 15000, lr = 0.01
I0921 19:04:00.665272  3264 solver.cpp:239] Iteration 15200 (0.206217 iter/s, 969.852s/200 iters), loss = 0.130351
I0921 19:04:00.679060  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0169842 (* 0.5 = 0.00849212 loss)
I0921 19:04:00.679067  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.972603
I0921 19:04:00.679074  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.0979947 (* 1 = 0.0979947 loss)
I0921 19:04:00.679080  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0238648 (* 1 = 0.0238648 loss)
I0921 19:04:00.679087  3264 sgd_solver.cpp:112] Iteration 15200, lr = 0.01
I0921 19:19:54.026827  3264 solver.cpp:239] Iteration 15400 (0.209787 iter/s, 953.347s/200 iters), loss = 0.292815
I0921 19:19:54.026943  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.030332 (* 0.5 = 0.015166 loss)
I0921 19:19:54.026952  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.931507
I0921 19:19:54.026957  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.262917 (* 1 = 0.262917 loss)
I0921 19:19:54.026962  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0147333 (* 1 = 0.0147333 loss)
I0921 19:19:54.026984  3264 sgd_solver.cpp:112] Iteration 15400, lr = 0.01
I0921 19:35:45.000252  3264 solver.cpp:239] Iteration 15600 (0.210311 iter/s, 950.973s/200 iters), loss = 0.137231
I0921 19:35:45.000366  3264 solver.cpp:258]     Train net output #0: bbox_loss = 0.0309661 (* 0.5 = 0.015483 loss)
I0921 19:35:45.000388  3264 solver.cpp:258]     Train net output #1: cls_Acc = 0.968037
I0921 19:35:45.000411  3264 solver.cpp:258]     Train net output #2: cls_loss = 0.109267 (* 1 = 0.109267 loss)
I0921 19:35:45.000418  3264 solver.cpp:258]     Train net output #3: landmark_loss = 0.0124809 (* 1 = 0.0124809 loss)
I0921 19:35:45.000428  3264 sgd_solver.cpp:112] Iteration 15600, lr = 0.01
I0921 19:38:32.950286  3264 solver.cpp:464] Snapshotting to binary proto file ../tmp/model/onet/0920/solver_iter_15636.caffemodel
I0921 19:38:32.950418  3264 net.cpp:842] Serializing 27 layers
I0921 19:38:32.966001  3264 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ../tmp/model/onet/0920/solver_iter_15636.solverstate
I0921 19:38:32.968122  3264 solver.cpp:311] Optimization stopped early.
I0921 19:38:32.996865  3264 caffe.cpp:253] Optimization Done.
ate_down: false
}
layer {
  name: "cls_loss"
  type: "OftenMtcnnSoftmaxLoss"
  bottom: "conv6-1-valid"
  bottom: "label-valid"
  top: "cls_loss"
  propagate_down: true
  propagate_down: false
}
layer {
  name: "cls_Acc"
  type: "OftenMtcnnAccuracy"
  bottom: "conv6-1-valid"
  bottom: "label-valid"
  top: "cls_Acc"
  include {
    phase: TRAIN
  }
}
layer {
  name: "conv6-2"
  type: "InnerProduct"
  bottom: "conv5"
  top: "conv6-2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_loss"
  type: "OftenMtcnnEuclideanLoss"
  bottom: "conv6-2"
  bottom: "bbox"
  bottom: "label"
  top: "bbox_loss"
  loss_weight: 0.5
  propagate_down: true
  propagate_down: false
  propagate_down: false
}
layer {
  name: "conv6-3"
  type: "InnerProduct"
  bottom: "conv5"
  top: "conv6-3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "landmark_loss"
  type: "OftenMtcnnLandMarkLoss"
  bottom: "conv6-3"
  bottom: "landmark"
  bottom: "label"
  top: "landmark_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  propagate_down: false
}
I0920 22:47:28.733198  3264 layer_factory.hpp:78] Creating layer PyData
I0920 22:47:29.488750  3264 net.cpp:84] Creating Layer PyData
I0920 22:47:29.488795  3264 net.cpp:380] PyData -> data
I0920 22:47:29.488952  3264 net.cpp:380] PyData -> label
I0920 22:47:29.488991  3264 net.cpp:380] PyData -> bbox
I0920 22:47:29.489013  3264 net.cpp:380] PyData -> landmark
